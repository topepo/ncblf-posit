---
title: "~~RStudio~~ Posit Tools for Data Science"
format:
  revealjs: 
    slide-number: true
    footer: <https://topepo.github.io/ncblf-posit>
    include-before-body: header.html
    include-after-body: footer-annotations.html
    theme: [default, tidymodels.scss]
    width: 1280
    height: 720
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"
---

```{r}
#| label: startup
#| include: false

options(digits = 4, width = 85)
options(dplyr.print_min = 6, dplyr.print_max = 6)
options(cli.width = 85)
options(crayon.enabled = FALSE)
options(pillar.advice = FALSE, pillar.min_title_chars = Inf)

library(gt)
```

## Who are we? 

Posit (n√©e RStudio) is a [public benefit corporation](https://posit.co/about/pbc-report/) that creates open source and commercial products for data science. 

As of this week, we are 381 people. About 50 people work solely on free open-source projects (about 40% - 50% of engineering). 

We are mostly remote, across almost every continent. HQ is in Boston. 


## Posit's Data Science Menu

We'll look at tooling for a couple of areas:

-   Data handling and manipulation
-   Visualization
-   Data analysis and modeling
-   Reporting
-   Potpourri for \$500

We'll mostly stick to R stuff but will accentuate a few python tools. 99% of what I'll talk about is free. 


# Data handling and manipulation

## Data ingestion

Getting your data in and formatting/manipulating it.

Data ingestion (not posit):

-   [`arrow`](https://arrow.apache.org/docs/r/): Read arrow files
-   [`sas7bdat`](https://cran.r-project.org/web/packages/sas7bdat/index.html): Read SAS files
-   R has a very rich set of data base tools (see the [Task Vew](https://cran.r-project.org/web/views/Databases.html))
-   [`duckdb`](https://github.com/duckdb/duckdb): DuckDB Database Management System

## Posit data ingestion

-   [`readr`](https://readr.tidyverse.org): Read excel files (.xls and .xlsx) into R
-   [`vroom`](https://vroom.r-lib.org/): Fast reading of delimited files
-   [`googlesheets4`](https://googlesheets4.tidyverse.org): Google Spreadsheets R AP
-   [`haven`](https://haven.tidyverse.org): Read SPSS, Stata and SAS files from R
-   [`rvest`](https://rvest.tidyverse.org): Simple web scraping for R

## Example code - tidyverse

```{r}
#| label: tv-load
#| message: true
library(tidyverse)
```

Not familiar with the tidyverse? Your best resource to learn is [*R for Data Science*](https://r4ds.hadley.nz).

## Reading in csv data

`Entries.csv` a 30mb file of daily train data:

```{r}
#| label: train-read
#| echo: true

system.time(raw_data <- read_csv("Entries.csv"))
```

## What's in that data set?

```{r}
#| label: train-str
#| echo: true

glimpse(raw_data)
```

Hmm. Let's get real dates

```{r}
#| label: dates
#| echo: true

raw_data <- 
  raw_data %>% 
  mutate(date = mdy(date))

class(raw_data$date)
```

## tidyverse and data manipluations

The code on the last slide accentuates how easy it is to code (and read code) when you need to do several things when using the pipe operator.

```{r}
#| label: pipes
#| echo: true
raw_data %>% 
  filter(station_id <= 40030 & date <= ymd("2001-01-06")) %>%
  select(-daytype, -station_id, Date = date) %>% 
  pivot_wider(id_cols = c(Date), 
              names_from = stationname, values_from = rides)
```

```{r}
#| label: stations
#| include: false
three_stations <- 
  raw_data %>% 
  filter(station_id <= 40030 & date <= ymd("2001-01-06")) %>%
  select(-daytype, -station_id, Date = date) %>% 
  pivot_wider(id_cols = c(Date), 
              names_from = stationname, values_from = rides)
```

## Data manipluation

Besides the tidyverse packages, there are a ton of open-source packages for manipulating data

-   [`glue`](https://glue.tidyverse.org): Glue strings to data in R. Small, fast, dependency free
-   [`forcats`](https://forcats.tidyverse.org/): Tools for working with categorical variables
-   [`fs`](hhttps://fs.r-lib.org/): Provide cross platform file operations
-   [`clock`](https://clock.r-lib.org/): A Date-Time Library for R
-   [`sparklyr`](https://spark.rstudio.com): R interface to Apache Spark

plus all of the `d{*}plyr` packages...

# Visualization

## ggplot

We'll, there's [`ggplot2`](https://ggplot2-book.org) and that covers a lot.

Some lesser known packages and tools...

## ggaminate

Animate your data or plots:

## plotly

## shiny 

It is is a popular R package and web application framework that makes it easy to tell data stories in interactive point-and-click web applications.

Two big things: 

 - The [visual UI editor](https://rstudio.github.io/shinyuieditor/articles/ui-editor-live-demo.html)
 - Shiny for [python](https://shiny.rstudio.com/py/)


# Data analysis and modeling

## A selection of our modeling tools

There is *a lot* to talk about here:

-   tidymodels
-   keras
-   torch
-   vetiver

## tidymodels

... is a framework for statistical and machine learning models using tidyverse syntax.

Basically caret on steroids. Can also access the [`h2o`](https://h2o.ai) modeling framework. 

If you want more details:

-   [RStudio conference keynote](https://www.rstudio.com/conference/2022/keynotes/applied-machine-learning/)
-   [tidymodels.org](https://www.tidymodels.org)
-   [*Tidy Modeling with R* book](https://www.tmwr.org)

## Preparing your data using recipes

The `recipes` package helps prepare your data prior to modeling. 

You can think of it as a better version of `model.matrix()` crossed with `dplyr`. 

Here's a hypothetical example: 

```r
rec <- 
  recipe(outcome ~ ., data = data_set) %>% 
  step_mutate(log_outcome = log10(outcome)) %>% 
  step_other(starts_with("zip"), threshold = 1 / 100) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_pca(all_numeric_predictors(), num_comp = 10)

```


## tensorflow/keras

(Mostly just called "tensorflow" now) These are deep learning libraries in python. 

There are a lot of tensorflow related R packages that access the *python* machine learning functionality (just like it does for C, java, etc).

An excellent R package called [`reticulate`](https://rstudio.github.io/reticulate/) provides the means to access all of python via R.

To get started, see the [tensorflow website](https://tensorflow.rstudio.com).

## torch

Another machine leaning library.

-   Rather than using python as an intermediary, it bundles the C++ files in the R package.

It can be used as an additional computing environment within R.

Some places to get more information:

-   [`brulee`](https://brulee.tidymodels.org) is an R package that has basic model implementations via torch.
-   the `torch` [package website](https://torch.mlverse.org)
-   [*Deep Learning and Scientific Computing with R torch* book](https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/) (new!)

## Vetiver

vetiver has [R](https://rstudio.github.io/vetiver-r/) and [python](https://rstudio.github.io/vetiver-python/stable/) implementations that enable simple deployment of models.

Overall documentation is at [*MLOps with vetiver*](https://vetiver.rstudio.com).

```{r}
#| label: vetiver
#| echo: false
#| fig-align: center
#| out-width: 50%

knitr::include_graphics("ml_ops_cycle.png")
```

# Reporting/Communicating

## **Quarto**!!!!

This is a new publishing system that does all of the things that Rmarkdown does (docs, pages, books, blogs) with a common syntax. 

 - Quarto is not built within R; it works with R, python, Julia, and Observable. 
 - Can publish to HTML, PDF, Epub, markdown, and so on. 
 - It encourages interactivity in documents. 
 - Plenty of examples for documents, websites, books and so on in the [gallery](https://quarto.org/docs/gallery/)
 
## Quarto

If you've used `knitr` and Rmarkdown, you will feel very comfortable with Quarto. 

Code chunks have options _in-line_: 

````
```{{r}}
#| label: fig-ggplot
#| fig-cap: !expr ggplot_cap
#| fig-width: 6
#| fig-height: 4.25
#| out-width: 70%

mtcars %>% ggplot(aes(disp, mpg)) + geom_point()
```
````

## The gt package

People seem to _loooove_ tools for making tables in documents. 

The [`gt`](https://gt.rstudio.com) package is a nice addition to set of table packages. 

```{r}
#| label: gt-code
#| eval: false
library(gt)
three_stations %>% 
  gt() %>% 
  tab_header(
    title = "Chicago Train Ridership",
  ) %>%
  tab_spanner(
    label = "Riders/Day",
    columns = c(-Date)
  )
```

## 

```{r}
#| label: gt-res
#| echo: false
library(gt) 
three_stations %>% 
  gt() %>% 
  tab_header(
    title = "Chicago Train Ridership",
  ) %>%
  tab_spanner(
    label = "Riders/Day",
    columns = c(-Date)
  )
```


# Potpourri

## webR

This is a good example of how we are often competing with ourselves. 

webR is a tool that will compile R into machine readable code and embed it in a website. 

All of the resources are from your local machine. [Let's play!](https://webr.r-wasm.org/latest/)


Good summaries: 

 - ["webR 0.1.0 has been released"](https://www.tidyverse.org/blog/2023/03/webr-0-1-0/)
 - ["How to run R code in the browser with webR"](https://blog.djnavarro.net/posts/2023-04-09_webr/)
 - ["WebR: R compiled for WebAssembly and running in the browser"](https://www.rstudio.com/conference/2022/talks/webr-r-compiled-for-webassembly/)